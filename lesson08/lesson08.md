## Урок 8. Хранилища данных
#### Финальные вопросы
* **Что такое Hadoop?** <br>
Это некий фреймворк для работы с BigData, включающий в себя набор инфраструктурных инструментов `Hadoop Common`, 
распределенную файловую систему `HDFS`, планировщик заданий и менеджер ресурсов `YARN`, 
а также `Hadoop MapReduce` - программная среда для разработки заданий на распределенное вычисление

* **Что такое HDFS?** <br>
`HDFS` - распределенная файловая система

* ***Что такое YARN?** <br>
`YARN` - планировщик заданий и менеджер ресурсов в экосистеме Hadoop

* **Какие минусы или опасные места HDFS?** <br>
Главное узкое место данной файловой системы - скорость работы на запись (из-за необходимости репликации) 
и большой размер блока по-умолчанию, вследствии чего запись большого количества мелких файлов быстро приведет к 
исчерпанию дискового пространства.

* **Что такое блок HDFS?** <br>
**Блок HDFS** - минимальная единица данных, которая может храниться в файловой системе

* **Для чего используется NameNode?** <br>
**NameNode** используется для хранения метаинформации о распределении файлов по блокам.

* **Для чего используется DataNode?** <br>
**DataNode** исползуется для хранения блоков данных.

* **Что будет, если записать много маленьких файлов в HDFS?** <br>
Быстро закончится место на диске.

* **Что будет, если несколько DataNode внезапно отключатся?** <br>
Данные будут забираться с других DataNode.

* **Как проадпейдить несколько записи в большом файле на hdfs?** <br>
Сначала удалить файл, потом залить обновленный файл.

* ***Почему задачи на YARN нестабильны?** <br>
Потому что сложно добиться сбалансированности раздачи ресурсов при выполнении задач.

* **Что такое Hive?** <br>
**Hive** - это СУБД для работы с данными в **Hadoop**. 
Используется для удобства доступа к данным в HDFS, т.к. позволяет обращаться к ним при помощиь SQL-подобного языка.

* **Что хранит Hive Metastore?** <br>
Hive Metastore хранит метаданные о схемах таблиц и их физическом расположении в HDFS

* **Чем отличается external table и managed table?** <br>
External table - тип таблиц, испозующие внешние файлы в качестве данных.
Например, CSV-файл можно подключить в виде external table в Hive. При удалении файла не черезе Hive - нужно обновлять метаданные.
А если удалить таблицу в Hive - файлы остаются на месте.
Managed table - это внутренний тип таблиц, который полностью управляется через Hive.

* ***Какие форматы умеет читать Hive?** <br>
На 6-м занятии мы опробовали форматы **AVRO**, **PARQUET** и **ORC**.
Помимо этого, Hive понимает простые форматы **Text format**, **Key-Value format** и **Sequence format**.

* ***Чем отличается управление ресурсов в Hive и Impala?** <br>
1) Hive использует MapReduce, преобразуя SQL-запросы в задания Hadoop, а Impala использует параллельную обработку (MPP)
2) Impala обрабатывает SQL-запросы на лету, а Hive нет.
3) Простые запросы быстрее выполняются в Impala, сложные - в Hive
4) Hive является отказоустойчивой системой, которая сохраняет все промежуточные результаты. У Impala такого нет.

* **Чем отличается колоночный формат хранения данных от строчного?** <br>
В колоночном формате данные хранятся по колонкам, 
т.е. если нам нужно прочитать только несколько полей за какой-то период - будут прочитаны только несколько колонок.
А если бы это был строчный формат - то вычитывались бы все поля и только потом происходила фильтрация по набору полей.


* **Чем отличается parquet/orc от csv?** <br>
Parquet и ORC - это колоночные форматы, а CSV - строчный.
Parquet и ORC - оптимизированы для работы с большими данными, поддерживают сжатие. 
ORC поддерживает индексы. Самое главное - форматы позволяют читать только те данные, которые нужны.

* **Чем отличается Avro от json?** <br>
Avro - это строчный формат, который хранит схему данных в формате JSON, а данные уже в бинарном формате или JSON.

* ***Чем отличается документориетированный формат данных от реляционного?** <br>
Реляционный формат подразумевает высокую связность данных, строгую типизацию и заранее заданную структуру,
а документоориентированный формат всего этого может не иметь. 

* **Чем отличается etl и elt?** <br>
ETL обозначает извлечение, преобразование и загрузку данных, в то время как ELT обозначает извлечение, загрузку и только потом преобразование данных.
Поэтому ETL логично использовать для извлечения изначально структурированных данных, а ELT - для структурированных и неструктурированных данных.
Преобразование в ETL производится до загрузки в хранилище, а в ELT - уже после загрузки в хранилище, что позволяет при ELT-подходе не утратить сырые данные.

* **Какие основные челенджы etl?**  <br>
В ETL основные этапы - это извленечине данных из разных источников, потом их нужно преобразовать к удобоваримому формату - 
чаще всего при помощи специальных сервисов, инструментов или скриптов, а потом уже загружаем все в хранилище в одном из оптимизированных форматов.

* ***Какие сложности стриминга в hdfs?** <br>

* ***Какие минусы key-value хранилищ?** <br>
Несоответствие принципам ACID, сильная привязанность к определенной СУБД, т.к. подобные хранилища используют не универсальный SQL-язык.

* **Из чего состоит хранилище данных?** <br>
Хранилище данных может состоять из ноборов обработанных данных, витрин данных, слоя ETL/ELT и метаданных.

* **Какие виды хранилищ данных вы знаете?** <br>
Если смотреть глобально, то есть два подхода Data Warehouse для хранения более структурированных данных и 
Data Lake - хранение любых данных, может включать в себя и DWH.

* ***Основные задачи Data governance?** <br>
1) Упрвление процессами извлечения, загрузки и преобразования данных
2) Мониторинг качества данных и состояния инфраструктуры
3) Подготовка дашбордов для конечных пользователей - DS и DA.